{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18237674",
   "metadata": {
    "id": "18237674"
   },
   "source": [
    "# Machine-Learning Based Natural Language Processing\n",
    "# Lab 1 - Text Processing and Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2c3bf",
   "metadata": {
    "id": "57d2c3bf"
   },
   "source": [
    "---\n",
    "In this session, we will teach you how to approach processing a text-based dataset, with the goal of training a classifier, based on classical machine learning techniques. We've chosen __stance detection__ as an example of a document classification task.\n",
    "\n",
    "We will perform some preprocessing on data, see how to transform textual data into feature vectors, how to train several algorithms, as well as how to evaluate the trained models.  We will make use of the sklearn machine learning library in Python.\n",
    "\n",
    "These are the topics we will cover:\n",
    " * Data Exploration\n",
    " * Text processing\n",
    " * Feature Extraction\n",
    " * Classification Models\n",
    " * Evaluation\n",
    " * Regularization\n",
    " * Kaggle competition (*)\n",
    "\n",
    "(\\*) As a **bonus**, we'll have a friendly Kaggle competition to see who can get the highest performance for stance prediction on a held out test set. We want you to critically think about how to improve and generalize your model's performance!\n",
    "\n",
    "\n",
    "## General instructions:\n",
    "- Complete the code where needed\n",
    "- Provide answers to questions only in the cell where indicated\n",
    "- **Do not alter the evaluation cells** (`## evaluation`) in any way as they are needed for the partly automated evaluation process. Please note that some of your outcomes will be dependent on the sklearn version used by your system. We have tested the notebook on Google Colab, so we can only guarantee that the evaluations work as expected on that platform. **Please run the notebook on Google Colab (it's free and easy to use), or otherwise ensure that you have installed identical versions of each package on your own device when running locally.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cf0f6",
   "metadata": {
    "id": "154cf0f6"
   },
   "source": [
    "---\n",
    "## Machine Learning in Python\n",
    "\n",
    "Python is the most widely used programming language among data scientists and machine learning engineers, next to R, Matlab and SQL (although the latter is not a programming language in the strict sense). It is very readable and development times are usually quite fast, which makes it the perfect language to do rapid prototyping and to toy around with your ideas. It has also become an entire ecosystem on its own among data scientists: a plethora of GitHub data science repositories exist, which you can use in your own projects; if you have some data science problem, chances are people have already worked on it in the past and have open-sourced their code. And finally, Python is the language of choice if you want to experiment with deep learning -- the latest 'big leap' in machine learning -- since the most mature and most widely used frameworks (PyTorch, Tensorflow and Keras) provide very easy-to-use Python interfaces.\n",
    "\n",
    "In this lab session, we will explore Python for natural language processing tasks, more specifically text processing and classification. We will focus on libraries often used for text processing and machine learning tasks, such as Pandas, Scikit-learn and the Natural Language Toolkit (NLTK).\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.dropbox.com/s/vejqgrjfaoa5o3w/scikit-learn-logo.png?dl=1\" style=\"max-width: 120px; display: inline\" />\n",
    "<img src=\"https://www.dropbox.com/s/3bshsaj5bzutf0m/numpy-logo.png?dl=1\" style=\"max-width: 120px; display: inline\" />\n",
    "<img src=\"https://www.dropbox.com/s/k89x8s0b7k5xacz/scipy-logo.png?dl=1\" style=\"max-width: 120px; display: inline\" />\n",
    "<img src=\"http://localhost:8888/static/base/images/logo.png\" style=\"max-width: 120px; display: inline\" />\n",
    "<img src=\"https://www.dropbox.com/s/xz09xye8svlh5fw/matplotlib-logo.png?dl=1\" style=\"max-width: 120px; display: inline\"/>\n",
    "<img src=\"https://www.dropbox.com/s/ubkr0bjx4mp70a9/pandas-logo.png?dl=1\" style=\"max-width: 120px; display: inline\" />\n",
    "</center>\n",
    "\n",
    "### Scikit-Learn\n",
    "\n",
    "* Machine learning library written in __Python__\n",
    "* __Simple and efficient__, for both experts and non-experts\n",
    "* Classical, __well-established machine learning algorithms__\n",
    "* Shipped with <a href=\"https://scikit-learn.org/stable/user_guide.html\">documentation</a> and <a href=\"https://scikit-learn.org/stable/auto_examples/index.html\">examples</a>\n",
    "\n",
    "### Pandas\n",
    "\n",
    "* Pandas is a library for __data manipulation and analysis__.\n",
    "* Pandas is designed to make it easier to work with structured data. Most of the analyses you might perform will likely involve using __tabular data__, e.g., from .csv files or relational databases (e.g., SQL).\n",
    "* A key class in pandas is the `DataFrame`, a two-dimensional tabular, column-oriented data structure where an element can be accessed by providing both its row and column label.\n",
    "* Documentation, guides and examples can be found <a href=\"https://pandas.pydata.org/docs/index.html\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabfd50e",
   "metadata": {
    "id": "aabfd50e"
   },
   "source": [
    "**Remark**: this lab session is self-paced, and we hugely encourage that you go out on the internet and become big friends with _Google_ and _StackOverflow_. No one has complete knowledge of the entire Python core, let alone knowing the most efficient methods to achieve a certain result. If you have a basic Python problem (e.g., \"how would I initialize a list of all zeros with a given length?\") you will definitely and easily find multiple answers on the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3975c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 1582,
     "status": "ok",
     "timestamp": 1707855603373,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "2f3975c7"
   },
   "outputs": [],
   "source": [
    "# if necessary, install the needed packages by uncommenting the following lines:\n",
    "# ! conda install numpy scipy scikit-learn jupyter matplotlib  -y\n",
    "# ! conda install python-graphviz -y\n",
    "# ! pip install pydotplus\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# General machine Learning\n",
    "import sklearn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# For reproducability\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f0841",
   "metadata": {
    "id": "7c8f0841"
   },
   "source": [
    "---\n",
    "## Stance Detection\n",
    "\n",
    "Stance detection is the extraction of a subject's reaction to a claim made by a primary actor.\n",
    "In the context of this task, we define stance detection as automatically determining from text whether the author is in favor of the given target, against the given target, or whether neither inference is likely. Consider the target--tweet pair:\n",
    "\n",
    "\n",
    "```\n",
    "Target: legalization of abortion\n",
    "Tweet: A foetus has rights too! Make your voice heard.\n",
    "```\n",
    "\n",
    "Humans can deduce from the tweet that the speaker is likely against the targetted claim. The aim of the task is to test automatic systems in determining whether we can deduce the stance of the tweeter.\n",
    "\n",
    "Stance detection plays a major role in analytical studies measuring public opinion on social media, particularly on political and social issues. The nature of these issues is usually controversial, wherein people express opposing opinions toward\n",
    "differentiable points.\n",
    "\n",
    "We will analyze Dutch tweets as collected by the website [twiqs.nl](https://twiqs.nl) (Tjong Kim Sang and van den Bosch 2013) from the period from March 12th, 2020 (the date of the first Dutch national pandemic press conference) to March 31st, 2021. This data set contains about 20 million tweets per month of which about 13% are pandemic tweets, extracted by a hand-crafted query containing 67 tokens like corona, vaccine, pandemic, curfew and patient (Tjong Kim Sang et al. 2021). In this exercise we will determine the stance of users on the measure of social distancing against COVID-19.\n",
    "\n",
    "<img src=\"https://gitlab.ilabt.imec.be/T2K/ugainbigdata_public/-/raw/master/img//stance.png\" width=100% >\n",
    "\n",
    "Three different labels can be assigned to a tweet: *__Support (EENS)__*, if the tweet author supports the related pandemic measure, *__Reject (ONEENS)__*, if the tweet author rejects the measure, and *__Irrelevant (ANDERS)__*, if a tweet is not relevant for the measure or if the opinion of the sender could not be determined.\n",
    "A subset of the social distancing tweets (898) was annotated by a second annotator. The inter-annotator agreement or Cohen Kappa coefficient was Îº = 0.55 which indicates that labeling was a hard task (for more information on the Cohen Kappa metric we refer to its page [Wikipedia](https://en.wikipedia.org/wiki/Cohen%27s_kappa)).\n",
    "\n",
    "The described dataset has been provided in CSV format. Pandas will now be used to read the dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rUPB0wi98dZt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2157,
     "status": "ok",
     "timestamp": 1707855613497,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "rUPB0wi98dZt",
    "outputId": "fd0bd4c0-54e5-4b67-b2a9-cbfbfae4efc3"
   },
   "outputs": [],
   "source": [
    "!wget \"https://www.dropbox.com/s/brhwpht2tynabnu/data.zip?dl=1\" -O data.zip\n",
    "!unzip -o data.zip\n",
    "!rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd5264",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1707855615512,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "69cd5264",
    "outputId": "8cb37ec4-70d3-4aa7-e284-c4c36c72931c"
   },
   "outputs": [],
   "source": [
    "# load in stance detection dataset\n",
    "filepath = \"train.csv\"\n",
    "data = pd.read_csv(filepath, sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c76c9",
   "metadata": {
    "id": "bf1c76c9"
   },
   "source": [
    "Note that the tweet dataset contains much more information than simply the text of the tweet. While indicators such as the number of retweets or favorites might be useful for stance detection, we will focus on the \"text\" field itself (since, of course, this is still an NLP course)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b936d11",
   "metadata": {
    "id": "6b936d11"
   },
   "source": [
    "## 1. Data exploration\n",
    "\n",
    "The first step you should think of when you get your hands on a new dataset, is data exploration. This means getting familiar with all the aspects of the data by solving queries and visualizing its properties. There are many useful Python visualization libraries which can make this task easier, such as <a href=\"https://matplotlib.org/\"> Matplotlib </a> or <a href=\"https://seaborn.pydata.org/\"> Seaborn </a>.\n",
    "\n",
    "We start with some warm-up questions to help you get familiar with the dataset. Because you're all familiar with Python already, the focus of the lab session will not be on more advanced data exploration and visualization tasks, though you should not underestimate the importance of this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3945529",
   "metadata": {
    "id": "a3945529"
   },
   "source": [
    "**Question**: How many tweets are included in the collection?\n",
    "\n",
    "**Question**: How many different words are used in the tweets? For now, you can assume that all words are separated by a space. Watch out not to count leading or trailing spaces as words. Hint: take a look at the default setting of the \"split\" function for strings.\n",
    "\n",
    "**Question**: How many times do each of the stances occur in the data? Remember that the following labels are used in the dataset: \"EENS\" (agree), \"ONEENS\" (disagree), \"ANDERS\" (neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786f42a",
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1707855630876,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "f786f42a"
   },
   "outputs": [],
   "source": [
    "# n_tweets = ... (number of tweets in the collection)\n",
    "# n_words = ... (number of different words in the collection)\n",
    "# n_agree, n_disagree, n_neutral = ... (number of times the stances occur in the data)\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd53bc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1707855637258,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "3fd53bc4",
    "outputId": "87ef6afc-d996-4519-a712-09ba98f256fe"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert n_tweets == 3636, \"Number of tweets is not correct\"\n",
    "assert n_words == 20140, \"Number of words in vocabulary is not correct. Please ensure that no whitespaces are counted as words.\"\n",
    "assert n_agree == 2181, \"Number of stance occurrences is not correct\"\n",
    "assert n_disagree == 604, \"Number of stance occurrences is not correct\"\n",
    "assert n_neutral == 851, \"Number of stance occurrences is not correct\"\n",
    "print('well done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501d227",
   "metadata": {
    "id": "8501d227"
   },
   "source": [
    "As an illustration, below is code to visualize the word frequencies in a word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926026a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 12251,
     "status": "ok",
     "timestamp": 1707855656593,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "0926026a",
    "outputId": "022b5c2c-eef1-4566-fc5c-226be15611fc"
   },
   "outputs": [],
   "source": [
    "# Word cloud\n",
    "\n",
    "# if necessary, install the needed packages by uncommenting the following line:\n",
    "! pip install wordcloud nltk\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = stopwords.words(\"dutch\")\n",
    "\n",
    "# Store text from pandas data frame in list\n",
    "text = ' '.join(data['text']) # join all tweets in training set\n",
    "print('Example text:\\n', data['text'][0])\n",
    "\n",
    "# limit word count\n",
    "wordcount = 1000\n",
    "# stop words\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"br\")\n",
    "print('\\nDutch stopwords:\\n', ', '.join(sorted(list(stopwords))))\n",
    "\n",
    "# setup word cloud\n",
    "wc = WordCloud(scale=3, background_color=\"white\", max_words=wordcount, stopwords=stopwords, width=800, height=600)\n",
    "\n",
    "# generate word cloud\n",
    "wc.generate(text)\n",
    "\n",
    "# show\n",
    "print('\\nWordcloud:')\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0fbdc5",
   "metadata": {
    "id": "ad0fbdc5"
   },
   "source": [
    "## 2. Text processing\n",
    "\n",
    "In the remainder of the lab session, we will focus on textual data. Performing analytics, business intelligence, machine learning, etc. on (written) text is called Natural Language Processing (NLP) in academics. In the next few exercises we will learn the necessary skills and steps in preparing and transforming text into useful data that can be used in a wide variety of powerful machine learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WJTvm3UP-E6N",
   "metadata": {
    "id": "WJTvm3UP-E6N"
   },
   "source": [
    "### 2.1. Cleaning and preprocessing\n",
    "\n",
    "The very first step in NLP is _preprocessing_, that is, preparing the raw textual data such that we get rid of (most of the) noise and retain the most informative signal. Consider for example the following tweet, and how we can apply multiple possible preprocessing steps to arrive at a noise-free tweet. __All steps are optional__ and one should always consider the application at hand to determine which preprocessing steps are needed!\n",
    "\n",
    "> HEY @UGentstudent! This isn't a clean #NLP tweet :-D http://www.ugent.be\n",
    "\n",
    "__Step 1__ - Convert all characters to lowercase. By doing this, the words _'This'_ and _'this'_ become the same, which is what we want.\n",
    "\n",
    "> hey @ugentstudent! this isn't a clean #nlp tweet :-d http://www.ugent.be\n",
    "\n",
    "__Step 2__ - Apply normalization, for example:\n",
    " * Replacing all numbers by a single character, e.g. 0.\n",
    " * Replacing all characters with accents by their clean counterpart, e.g. Ã© becomes e.\n",
    " * Expanding popular contractions such as _\"isn't\"_ to _\"is not\"_.\n",
    " * ...\n",
    "\n",
    "> hey @ugentstudent! this is not a clean #nlp tweet :-d http://www.ugent.be\n",
    "\n",
    "__Step 3__ - Remove unwanted words, punctuation, URLs, whitespaces... For example, we could choose to only retain alphanumerical chatacters, but this always depends on the application at hand. In our case, we will want to keep hashtags and mentions, but remove URLs and emoticons/emojis.\n",
    "\n",
    "> hey @ugentstudent! this is not a clean #nlp tweet\n",
    "\n",
    "__Step 4__ - Splitting the text into separate words. This is a process called _tokenization_ and there exist many different methods of tokenizing a text. The most simple method finds all whitespaces and uses them to split the text. More advanced tokenizers also take into account punctuation and other textual markers. We will explore tokenization in detail in the next subsection.\n",
    "\n",
    "> ['hey', '@ugentstudent!', 'this', 'is', 'not', 'a', 'clean', '#nlp', 'tweet']\n",
    "\n",
    "__Step 5__ - Remove stop words. These are words that hardly contribute to the meaning of a text, such as \"the\", \"a\", \"an\", \"is\", \"and\", \"our\", etc. There are lists available of common stop words in English (e.g. https://gist.github.com/sebleier/554280) or other languages (which can be imported from the NLTK library https://www.nltk.org/). Some lists include words such as \"not\", but such words can shape the semantic meaning of a text, so always be careful which words get removed from your text.\n",
    "\n",
    "> ['hey', '@ugentstudent', 'not', 'clean', '#nlp', 'tweet']\n",
    "\n",
    "__Step 6__ - In some applications (such a document classification) it can also be useful to apply _stemming_ to the text (https://en.wikipedia.org/wiki/Stemming). Stemming essentially means that words are normalized, such that for example \"fishing\", \"fished\" and \"fisher\" all reduce to the same stem \"fish\". There exist many stemming algorithms (such as Porter stemming), but we will not cover stemming in detail here.\n",
    "\n",
    "We won't go into manual preprocessing and cleaning of tweets in this lab session, since it just comes down to applying some basic Python functions. As we will see later, there exist Python libraries with many options for automatic text cleaning and processing, which are ready for application in your own projects. Usually, there is little need for rewriting the existing functionality and it is just a matter of combining the right settings for your specific problem.\n",
    "\n",
    "For now, we provide the following function, which receives a tweet's text as an input and outputs the cleaned version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae883912",
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1707855668383,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "ae883912"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "punct = {'ð', '[', 'â', '~', 'ðª', 'ð', 'ð¡', '-', 'ð£', 'ðº', 'â', 'Ì¶', '\\u200a', ';', 'ð', ' ', '!', '%', ',', 'ð', 'Â®', 'ð', '?', 'ð½', '=', 'ð¨', 'â', 'â', ')', '|', 'â', '\\xa0', 'ð½', '&', 'ð¼', 'Â¿', 'â¦', 'ð', 'ð', 'â', 'ð§', 'ð', 'ð', '+', 'ð¤', 'ð', 'â', 'Â¡', 'ð¤', 'ï¸', 'ð¸', '@', 'ð¸', ':', 'â', 'â¢', 'ð¿', 'ð»', 'ð', 'ð', 'â', ']', 'â', '\"', '\\u200b', 'ð¤', '\\n', '.', '(', '$', 'â¤', 'â¬', '#', 'ð', \"'\", '/', '*', 'ð¾', 'â', 'ð¿'}\n",
    "\n",
    "punct.remove(' ')  # keep spaces\n",
    "punct.remove('#')  # keep hashtags\n",
    "punct.remove('@')  # keep mentions\n",
    "punct.remove('\\'') # keep single quotes (in order to retain I'm, isn't, etc.)\n",
    "\n",
    "def clean(text):\n",
    "    temp_text = text.lower()\n",
    "    temp_text = re.sub(r'https?://\\S+', '', temp_text)\n",
    "    temp_text = re.sub(r'\\d+', '0', temp_text)\n",
    "    temp_text = temp_text.replace('â', '\\'')  # some single quotes are slanted, and we want to retain them\n",
    "    for p in punct:\n",
    "        temp_text = temp_text.replace(p, ' ')\n",
    "    temp_text = re.sub(r'\\s+', ' ', temp_text)\n",
    "    cleaned_text = temp_text.strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab848a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1707855670251,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "22ab848a",
    "outputId": "cf31c1ec-ff35-4fd1-a012-76d1ce8c8721"
   },
   "outputs": [],
   "source": [
    "tweet_text = data[\"text\"].iloc[0]\n",
    "cleaned_tweet = clean(tweet_text)\n",
    "print(\"Original tweet: \"+ tweet_text)\n",
    "print(\"Cleaned tweet: \"+cleaned_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25ad95",
   "metadata": {
    "id": "5f25ad95"
   },
   "source": [
    "### 2.2. Tokenization\n",
    "\n",
    "Tokenization is the process of splitting a text into a sequence of separate words. It is an essential step in NLP, since words are the most basic building blocks that provide a meaning or sentiment to any text. Natural language models therefore often work with words as input features (although in some models the separate characters themselves are used instead of words).\n",
    "\n",
    "The most basic type of tokenization is to split the text whenever a whitespace occurs, as we did earlier. This usually works pretty well, but one might need some additional functionality. For example, in English, we would like words such as *couldn't* to be expanded to *could* and *not*. A useful tool is Python's Natural Language ToolKit (NLTK library), which contains many methods and algorithms to automatically tokenize a text. For example, it contains a specific Twitter-aware tokenizer.\n",
    "\n",
    "**Question**: Write a function that tokenizes the input \"tweet_text\" using the TweetTokenizer from the tokenizer module (https://www.nltk.org/api/nltk.tokenize.html). The output is a list of tokens extracted from the input tweet (hint: a quick Google-search can provide you with many examples of how this tokenizer is used).\n",
    "\n",
    "We have already provided the structure of the function, together with its input and output. Please fill in the part in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3f232",
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1707855680009,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "3ed3f232"
   },
   "outputs": [],
   "source": [
    "# import tweet tokenizer from NLTK and tokenize argument 'tweet_text'\n",
    "# ...\n",
    "# tknzr = ...\n",
    "# tweet_tokens = ...\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def tokenize(tweet_text):\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "    return tweet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20065752",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707855681619,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "20065752",
    "outputId": "6330c15d-a2e4-44de-a1d6-192309e6f853"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "tweet_tokens = tokenize(cleaned_tweet)\n",
    "\n",
    "assert len(tweet_tokens)==23, \"Did you tokenize correctly? Used the TweetTokenizer?\"\n",
    "assert tweet_tokens[4] == \"zaak\", \"Did you tokenize correctly? Used the TweetTokenizer?\"\n",
    "print('well done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700c15b",
   "metadata": {
    "id": "6700c15b"
   },
   "source": [
    "One reason to use Python for machine learning (and NLP) is that thousands of fellow computer scientists and researchers are using it as well for that purpose. Chances are that whatever problem you are trying to tackle, someone has done it already. Regarding tweet tokenization, there are numerous GitHub projects to be found that have solved this problem, some better or more user-friendly than others. We have had pretty good experience with the following GitHub repository: https://github.com/erikavaris/tokenizer.\n",
    "\n",
    "For now, we will continue using the tweets tokenized with the NLTK TweetTokenizer. The code below adds a column to the original dataframe which contains the cleaned and tokenized version of the tweet text, for each tweet in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d367c",
   "metadata": {
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1707855691184,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "de6d367c"
   },
   "outputs": [],
   "source": [
    "data[\"cleaned\"] = data[\"text\"].apply(clean)\n",
    "data[\"tokenized\"] = data[\"cleaned\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905319da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1707855692609,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "905319da",
    "outputId": "bdd86a3f-8f86-4655-e827-f6dbcc4f1b30"
   },
   "outputs": [],
   "source": [
    "data[[\"text\", \"cleaned\", \"tokenized\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c21a18",
   "metadata": {
    "id": "72c21a18"
   },
   "source": [
    "### 2.3. Building a vocabulary\n",
    "\n",
    "For machine learning models it is important that datapoints have a numerical representation. Many machine learning models are vector-based, and each class of data is assigned to its own dimension in these vectors. What this means for us now, is that each word should be mapped to its own unique positive integer value. For example, consider a dictionary of the entire English language, then each word can be mapped to the position of that word in the dictionary. The sentence _\"blijf afstand houden\"_ can then be represented as a sequence of indices, e.g. [243, 5, 8723]. In other words, the text is transformed into a mathematical representation, which opens the gate to all sorts of powerful machine learning methods and models, which will be explored in later steps.\n",
    "\n",
    "We will now manually build a vocabulary for the Twitter dataset.\n",
    "\n",
    "**Question:** Use the `set` datastructure to find all unique words in the dataset, thereby using the tokenized tweets. How big is the vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa245f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1707855700673,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "0fa245f1",
    "outputId": "d1720ae5-dc18-4de9-e6fb-45b1ff155494"
   },
   "outputs": [],
   "source": [
    "# vocabulary = set()\n",
    "# ...\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f511929",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1707855715951,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "0f511929",
    "outputId": "d97b4111-11da-4b7c-d1b5-849fa7d35a4f"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert type(vocabulary) == set, \"Please use a set structure, to ensure every word in the vocabulary is unique\"\n",
    "assert len(vocabulary)>12190 and len(vocabulary)<12220, \"Size of vocabulary is not correct... Are you sure you used the tokenized tweets?\"\n",
    "print('well done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168e3a9",
   "metadata": {
    "id": "3168e3a9"
   },
   "source": [
    "**Question:** Now create a dictionary `word_to_ix` which maps a word to a unique index (from 0 up to the length of the vocabulary). Also, create a dictionary `ix_to_word` which does the opposite mapping. **Please ensure that the mapping is done alphabetically, by using the `sorted_vocabulary` (we have defined it for you). If w1 comes before w2 in alphabetical order, w1's index should be lower than w2's index.** Check if you can translate a word to an index, and use that index to find the original word again. What is the theoretical time complexity of a dictionary lookup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VrHU20wr1nFW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1707855722712,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "VrHU20wr1nFW",
    "outputId": "a30cf61e-c10a-46d7-82c8-2ea546c43d0e"
   },
   "outputs": [],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6324c84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1707855725572,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "f6324c84",
    "outputId": "620a901f-5fce-46e2-99c3-f47d580bb4cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create word_to_ix and ix_to_word dictionaries\n",
    "# word_to_ix = ...\n",
    "# ix_to_word = ...\n",
    "\n",
    "sorted_vocabulary = sorted(vocabulary) # Please ensure that this ordering is translated into the indices in your dictionary\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba842b08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1707855734606,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "ba842b08",
    "outputId": "eb28e809-9480-45c7-868c-27a83c90ed64"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert len(word_to_ix) == len(ix_to_word), \"Both dictionaries should have the same size\"\n",
    "assert word_to_ix[\"afstand\"] == 1675, \"Did you use the sorted vocabulary? Are you working on colab?\"\n",
    "assert ix_to_word[10870] == \"virtueel\", \"Did you use the sorted vocabulary? Are you working on colab?\"\n",
    "\n",
    "print(\"well done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92778a",
   "metadata": {
    "id": "1e92778a"
   },
   "source": [
    "Now that we have our vocabulary, it is possible to do some additional visualization to explore its properties. A more advanced exploration of the vocabulary can be useful to get inspiration for new features or additional processing steps necessary. Data cleaning and tokenization is usually an iterative process, where you will try out some new cleaning steps, visualize or investigate the resulting tokens and work out the additional necessary steps to obtain a clean dataset. For now, we will not go into this any further, and we will leave it at plotting the number of occurrences of words in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea329a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1707855743235,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "9aea329a",
    "outputId": "ce44ba21-60cb-427f-cc01-21e91691aab1"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_tokens = []\n",
    "for t in data['tokenized']:\n",
    "    all_tokens += t\n",
    "\n",
    "# Use counter to count the number of occurrences of each word in the vocabulary\n",
    "cnt = Counter(all_tokens)\n",
    "freq_list = cnt.values()\n",
    "\n",
    "plt.plot(list(freq_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff47f48",
   "metadata": {
    "id": "6ff47f48"
   },
   "source": [
    "## Supervised learning\n",
    "\n",
    "Now, we move on to the part of this lab session which deals with supervised machine learning.\n",
    "\n",
    "In __Supervised__ Machine Learning, we have a dataset consisting of both features and __labels__. The task is to predict the label of an object given a set of input features by learning a function that maps these features to an output based on example input-output pairs.\n",
    "Supervised learning is further broken down into two categories, __classification__ and __regression__. In classification, the label is __discrete__, while in regression, the label is __continuous__.\n",
    "\n",
    "Data comes as a set ${\\cal D} = (X, y)$ where\n",
    "* Input samples are given as an array $X$ of shape `n_samples` $\\times$ `n_features`, taking their values in ${\\cal X}$;\n",
    "* Output values are given as an array $y$, taking _symbolic_ values in ${\\cal Y}$.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/kn9t26hmth9ir18/jakevdp_features.png?dl=1\">\n",
    "\n",
    "The goal of supervised classification is to build a function $f: {\\cal X} \\mapsto {\\cal Y}$ minimizing the expected error over the training data:\n",
    "\n",
    "$$\n",
    "Err(\\varphi) = \\mathbb{E}_{X,Y}\\{ \\ell(Y, \\varphi(X)) \\}\n",
    "$$\n",
    "\n",
    "where $\\ell$ is a loss function, e.g., the zero-one loss for classification $\\ell_{01}(Y,\\hat{Y}) = 1(Y \\neq \\hat{Y})$.\n",
    "\n",
    "### Example Applications\n",
    "\n",
    "- Diagnosing disease from symptoms or clinical reports;\n",
    "- Language Translation;\n",
    "- Recognising cats in pictures;\n",
    "- Transcribing sign language from video to written text;\n",
    "- ...\n",
    "\n",
    "## 3. Feature extraction\n",
    "\n",
    "Now that we have the data, we need to build some sort of **feature representation** of our data. One of the simplest things we can do is to represent each sentence as a bag of its words.\n",
    "\n",
    "As a bag of words representation, we could use the collection of tokens that represent each tweet which we obtained in the previous section. However, we would like to show you an alternative way of tokenizing and building your vocabulary. The [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) module unifies the tokenization step, building a vocabulary and obtaining a **Bag of words** representation all in one module. The outcome is a set of features per record in our tweet dataset.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://gitlab.ilabt.imec.be/T2K/ugainbigdata_public/-/raw/master/img/bow.png\" style=\"max-width: 500px; display: inline\"  width=\"400px\"/>\n",
    "</center>\n",
    "\n",
    "The CountVectorizer module works as follows. It assigns a fixed integer id to each word occurring in any document of the training set (for instance by building a dictionary from words to integer indices). For each document #i, it counts the number of occurrences of each word w and stores it in X[i, j] (row i and column j in the feature matrix X) as the value of feature #j, where j is the index of word w in the dictionary. The bag of words representation implies that n_features is the number of distinct words in the corpus: this number is typically larger than 100,000.\n",
    "\n",
    "Fortunately, most values in X will be zeros since for a given document less than a few thousand distinct words will be used. For this reason we say that bags of words are typically high-dimensional **sparse** datasets. We can save a lot of memory by only storing the non-zero parts of the feature vectors in memory. *Scipy.sparse* matrices are data structures that do exactly this, and scikit-learn has built-in support for these structures.\n",
    "\n",
    "The Bag-of-words model is an orderless document representation â only the counts of words matter. For instance, in the example phrase _\"John likes to watch movies. Mary likes movies too\"_, the bag-of-words representation will not reveal that the verb _\"likes\"_ always follows a person's name in this text. As an alternative, the __n-gram model__ can store this information by encoding two consecutive tokens as single feature. Applying this to the same example, a bigram model will create a new index for the sequences _\"John_likes\"_, _\"likes_to\"_, _\"to_watch\"_, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074daf1",
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1707855751521,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "9074daf1"
   },
   "outputs": [],
   "source": [
    "# creating a tokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tokenizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed129c51",
   "metadata": {
    "id": "ed129c51"
   },
   "source": [
    "**Question**\n",
    "- Import a `CountVectorizer` from the `sklearn.feature_extraction.text` package.\n",
    "- Create a `CountVectorizer` object named `tokenizer`, with the following settings (have a look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)):\n",
    " - Specify the tokenizer to strip accents.\n",
    " - Create a tokenizer that learns unigrams as well as bigrams.\n",
    " - Reduce the tokenizer to remove stopwords, using the list of Dutch stopwords encoded in the variable *STOPWORDS*.\n",
    " - Only retain tokens that occur 2 or more times, and print the number of different words.\n",
    " - Reduce to only the 5.000 most often occurring tokens.\n",
    "- The `fit()` method of the vectorizer object learns a vocabulary dictionary of all tokens in the **raw** documents (`text` column in the dataset). Fit the tokenizer using `tokenizer.fit()` (you can use the text column from the tweet dataset).\n",
    "- Transform text from the training collection using `tokenizer.transform()` into a vector named `X`\n",
    "- Print the dimensions of the feature-matrix, `X`. Are they as expected?\n",
    "\n",
    "**Question**: Have a look at the vocabulary learned by the tokenizer (in other words, the dictionary words to indices used to create the feature matrix). What is the index of the token \"corona\"?\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**\n",
    "\n",
    "**Question**: Invert the vocabulary mapping, by mapping the indices to the corresponding tokens. Store it in the variable `inverted_vocab` and find out what token is represented by index 3000.\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6853b740",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1707855756656,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "6853b740",
    "outputId": "eeaf499d-9026-4766-f04b-15f46e0d18c8"
   },
   "outputs": [],
   "source": [
    "# import CountVectorizer\n",
    "# create CountVectorizer object with the specified settings\n",
    "# tokenizer = ...\n",
    "# X = ...\n",
    "# inverted_vocab = ...\n",
    "\n",
    "STOPWORDS = [\"aan\", \"al\", \"alles\", \"als\", \"altijd\", \"andere\", \"ben\", \"bij\", \"br\", \"daar\", \"dan\", \"dat\", \"de\", \"der\",\n",
    "             \"deze\", \"die\", \"dit\", \"doch\", \"doen\", \"door\", \"dus\", \"een\", \"eens\", \"en\", \"er\", \"ge\", \"geen\", \"geweest\",\n",
    "             \"haar\", \"had\", \"heb\", \"hebben\", \"heeft\", \"hem\", \"het\", \"hier\", \"hij\", \"hoe\", \"hun\", \"iemand\", \"iets\", \"ik\",\n",
    "             \"in\", \"is\", \"ja\", \"je\", \"kan\", \"kon\", \"kunne\", \"maar\", \"me\", \"meer\", \"men\", \"met\", \"mij\", \"mijn\", \"moet\", \"na\",\n",
    "             \"naar\", \"niet\", \"niets\", \"nog\", \"nu\", \"of\", \"om\", \"omdat\", \"onder\", \"ons\", \"ook\", \"op\", \"over\", \"reeds\", \"te\",\n",
    "             \"tegen\", \"toch\", \"toen\", \"tot\", \"u\", \"uit\", \"uw\", \"van\", \"veel\", \"voor\", \"want\", \"waren\", \"was\", \"wat\", \"werd\",\n",
    "             \"wezen\", \"wie\", \"wil\", \"worden\", \"wordt\", \"zal\", \"ze\", \"zelf\", \"zich\", \"zij\", \"zijn\", \"zo\", \"zonder\", \"zou\"]\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8fa452",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1707855758227,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "ca8fa452",
    "outputId": "ba615e00-8fec-49d3-9675-84e2f4781d56"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert X.shape == (3636, 5000), \"transform data['text'], make sure to limit the number of features to 5000\"\n",
    "assert tokenizer.strip_accents == 'ascii', \"set tokenizer strip accents\"\n",
    "assert tokenizer.ngram_range == (1, 2), \"set ngram range\"\n",
    "assert tokenizer.stop_words == STOPWORDS, \"set stop words\"\n",
    "assert tokenizer.min_df == 2, \"set minimum frequency\"\n",
    "assert inverted_vocab[360] == \"alsnog\", \"please invert the vocabulary\"\n",
    "\n",
    "print(\"well done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8800b7",
   "metadata": {
    "id": "fb8800b7"
   },
   "source": [
    "**Question**: Have a look at the feature representation of the first document `X[0]`. Keep in mind that the feature matrix is stored as a sparse matrix, for more information see [CSR_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) (hint: have a look at the method `nonzero`). What tokens do the indices in the feature representation correspond to?\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e633138",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1707855761014,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "6e633138",
    "outputId": "a7dfde3b-d041-4498-d3ff-bef1052f601a"
   },
   "outputs": [],
   "source": [
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9e7e7",
   "metadata": {
    "id": "3eb9e7e7"
   },
   "source": [
    "## 4. Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c34d4",
   "metadata": {
    "id": "a20c34d4"
   },
   "source": [
    "The goal of supervised classification is to build a function $f: {\\cal X} \\mapsto {\\cal Y}$ minimizing\n",
    "\n",
    "$$\n",
    "Err(f) = \\mathbb{E}_{X,Y}\\{ \\ell(Y, f(X)) \\}\n",
    "$$\n",
    "\n",
    "where $\\ell$ is a loss function, e.g., the zero-one loss for classification $\\ell_{01}(Y,\\hat{Y}) = 1(Y \\neq \\hat{Y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d690d3",
   "metadata": {
    "id": "a1d690d3"
   },
   "source": [
    "### 4.1. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3166b5",
   "metadata": {
    "id": "8e3166b5"
   },
   "source": [
    "**Decision Trees** are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a token occurs in a review or not), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "\n",
    "[A visual introduction to decision trees](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/yoq17ki09oy6nfq/jakevdp_decision_tree.png?dl=1\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e23b8b",
   "metadata": {
    "id": "c5e23b8b"
   },
   "source": [
    "**Question**\n",
    "- Import the `DecisionTreeClassifier` from the `sklearn.tree` module. [See documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- Create a `DecisionTreeClassifier` object named `dt_clf`; limit the number of leaf nodes to 10 and use information gain as criterion. **Be careful to set the *random_state* argument equal to the *SEED* variable we defined at the start of the lab session, to ensure reproducibility of your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bde89",
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1707855781602,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "b63bde89"
   },
   "outputs": [],
   "source": [
    "# from sklearn import decision tree classifier\n",
    "# dt_clf = ...\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80fcd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1707855783412,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "4b80fcd4",
    "outputId": "bf5d7dac-b867-4ce3-a9b8-8fa91847dea3"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert type(dt_clf) == sklearn.tree._classes.DecisionTreeClassifier, \"dt_clf should be instance sklearn Decision Tree, check your sklearn version\"\n",
    "assert dt_clf.max_leaf_nodes == 10, \"number of leaf nodes should be 10\"\n",
    "assert dt_clf.criterion == 'entropy', \"set criterion correctly\"\n",
    "\n",
    "print(\"well done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231b5f3",
   "metadata": {
    "id": "7231b5f3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to learn the \"best\" parameters for our model based on the training data, use scikit-learnâs `dt_clf.fit(features, vectors)` method. Inside this method, the parameters are fit according to some loss function.\n",
    "\n",
    "**Question**\n",
    "- Store the stance labels in a `y` variable\n",
    "- Fit the classifier object on the feature matrix X (which you created in the feature extraction step) by calling the `fit()` method\n",
    "- Show the list of classes learned by the classifier. Have a look at the documentation to know which attribute will give you this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02c2c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1707855786344,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "ad02c2c3",
    "outputId": "02cd5447-fa57-476a-95e8-3d5151acd293"
   },
   "outputs": [],
   "source": [
    "# y = ... (stance labels)\n",
    "# call fit() function on DecisionTreeClassifier object\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dfe7f",
   "metadata": {
    "id": "be5dfe7f"
   },
   "source": [
    "Below, we visualize the decision tree that was learned by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb46bcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1707855792557,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "7bb46bcb",
    "outputId": "0adce256-77f8-4ff8-a551-5f1a68949daf"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "dot_data = export_graphviz(dt_clf,\n",
    "                           feature_names=tokenizer.get_feature_names_out(),\n",
    "                           filled=True,\n",
    "                           rounded=True,\n",
    "                           special_characters=True, class_names=dt_clf.classes_)\n",
    "graph = pydotplus.graphviz.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137584d",
   "metadata": {
    "id": "2137584d"
   },
   "source": [
    "**Question**: What feature is tested first? Do the features that are tested by this decision tree correspond with your intuition?\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab00d33",
   "metadata": {
    "id": "bab00d33"
   },
   "source": [
    "### 4.2. Logistic regression\n",
    "\n",
    "__Logistic regression__ models the probability $P(y|x;w)$ that a tweet, $x$, falls into the specific category or not ($y \\in \\{0,1\\}$). In the case of our three categories, it uses a different vector of weights $w$ for every category (ANDERS, EENS, ONEENS). If $P(y=1|x;w)$ > 0.5, then the feature vector falls into the category corresponding to the weight vector $w$.\n",
    "\n",
    "The following are the building blocks of a logistic regression classifier:\n",
    "\n",
    "- Bag-of-Words vector\n",
    "$$x = [x_1,x_2,...,x_{|V|}], x \\in \\mathbb{R}^{|V|} $$\n",
    "\n",
    "- Parameter vector (one per class)\n",
    "$$w = [w_{1},w_{2},...,w_{|V|}], w \\in \\mathbb{R}^{|V|} $$\n",
    "\n",
    "- Linear scoring function $f$\n",
    "$$f_w{(x)} = w_1x_1+w_2x_2+...+w_{|V|}x_{|V|} = w^Tx \\in \\mathbb{R}$$\n",
    "\n",
    "- Sigmoid Function\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}} \\in [0,1]$$\n",
    "\n",
    "As $z$ goes from $-\\infty$ to $\\infty$, $\\sigma(z)$ goes from 0 to 1\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/tt0q4ktc4na12yr/sigmoid.png?dl=1\">\n",
    "\n",
    "$$P(y=\\text{1}|x;w) = \\sigma(f_w(x)) = \\frac{1}{1+e^{-(w^Tx)}}$$\n",
    "\n",
    "$$log P(y=\\text{1}|x;w)= - log(1+e^{{-(w^Tx)}}) $$\n",
    "\n",
    "\n",
    "**Learning** is formulated as maximizing the likelihood of the correct answer or minimizing the negative log of the likelihood (probability) of the correct answer\n",
    "\n",
    "\n",
    "$$ \\underset{\\text{w}\\in R^{|V|}}{min}\\sum_{i}^{N} log(1+e^{{-(w^Tx)}}) $$\n",
    "\n",
    "If $\\sigma(f(x))$ > 0.5 then feature vector x is predicted to belong to category y.\n",
    "\n",
    "In our setting of stance detection with multiple output categories (>2), logistic regression is trained for every label separately (meaning a different weight vector is trained for each category), and then the most probable category is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf03ad",
   "metadata": {
    "id": "dfaf03ad"
   },
   "source": [
    "**Question**:\n",
    "- Import `LogisticRegression` from the `sklearn.linear_model` module ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)).\n",
    "- Create a new `LogisticRegression` object named `lr_clf`. **Again, please set the `random_state` argument equal to the SEED variable we defined earlier.**\n",
    "- Fit the model on our training data.\n",
    "- The feature-weights $w$ that are learned by the classifier, and the tokens they correspond to, can be accessed using `lr_clf.coef_`. Weights provide insights into important features. Which tokens are weighted strongly for classes EENS and ONEENS? Print the ten most significant tokens for each class by sorting the lists of tokens according to weight. Using numpy's [argsort](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) method can be convenient here. Remember that the dictionary `inverted_vocab` (which you defined earlier) can be used translate token id's (which are used as features in the model) to tokens.\n",
    "\n",
    "**Question**: What is the weight of token `zegneetegenanderhalvemeter` for each of the three classes? Do the weights correspond with what you would expect intuitively?\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5df7e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1707855803703,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "be5df7e5",
    "outputId": "76256d0c-2d8b-467e-bc92-3fcf6e5397d0"
   },
   "outputs": [],
   "source": [
    "# import Logistic regression classifier and fit on your data\n",
    "# lr_clf = ... (random_state=SEED)\n",
    "\n",
    "# agree_features = ... # list of 10 token ids, ordered from highest to lower weight assigned by the model for the \"EENS\" class\n",
    "# disagree_features = ... # list of 10 token ids, ordered from highest to lower weight assigned by the model for the \"ONEENS\" class\n",
    "\n",
    "# agree_tokens = ... # list of 10 tokens, ordered from highest to lower weight assigned by the model for the \"EENS\" class\n",
    "# disagree_tokens = ... # list of 10 tokens, ordered from highest to lower weight assigned by the model for the \"ONEENS\" class\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e509518",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1707855814898,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "3e509518",
    "outputId": "9f4d1b04-17f9-4413-92a6-dbaf988692f0"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert type(lr_clf) == sklearn.linear_model._logistic.LogisticRegression, \"wrong classifier\"\n",
    "assert abs(lr_clf.coef_[0][2] - 0.3240) <= 1e-4, \"Have you fit the classifier? Have you set the seed? Are you working in colab?\"\n",
    "assert agree_features[0] == 1985, 'use np.argsort to get list of agree token ids'\n",
    "assert disagree_features[0] == 4523, 'use np.argsort to get list of disagree token ids'\n",
    "assert agree_tokens[0] == 'houdafstand', 'use the inverted vocabulary to map ids to tokens'\n",
    "assert disagree_tokens[0] == 'waanzin' , 'use the inverted vocabulary to map ids to tokens'\n",
    "\n",
    "print(\"well done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb348d2a",
   "metadata": {
    "id": "cb348d2a"
   },
   "source": [
    "### 4.3. Naive Bayes Classification\n",
    "\n",
    "__Naive Bayes classifiers__ are built on Bayesian classification methods.\n",
    "These rely on Bayes's theorem, which is an equation describing the relationship of __conditional probabilities__ of statistical quantities.\n",
    "In Bayesian classification, we're interested in finding the probability of a label $y$ given some observed features, which we can write as $P(y~|~{\\rm x})$.\n",
    "Bayes's theorem tells us how to express this in terms of quantities we can compute more directly:\n",
    "\n",
    "$$\n",
    "P(y~|~{\\rm x}) = \\frac{P({\\rm x}~|~y)P(y)}{P({\\rm x})}\n",
    "$$\n",
    "\n",
    "If we are trying to decide between three stancesâthen one way to make this decision is compute the posterior probabilities for each label:\n",
    "\n",
    "$$\n",
    "\\underset{y \\in \\{\\text{EENS}, \\text{ONEENS}, \\text{ANDERS}\\}}{\\text{argmax}} P(y|x)\n",
    "$$\n",
    "\n",
    "This requires us to model the probability $P({\\rm x}~|~y)$ for each label.\n",
    "Such a model is called a *generative model* because it specifies the hypothetical random process that generates the data.\n",
    "Specifying this generative model for each label is the main piece of the training of such a Bayesian classifier.\n",
    "The general version of such a training step is a very difficult task, but we can make it simpler through the use of some simplifying assumptions about the form of this model.\n",
    "\n",
    "This is where the \"naive\" in \"naive Bayes\" comes in: if we make very naive assumptions about the generative model for each label (i.e., the independence of co-occuring words), we can find a rough approximation of the generative model for each class, and then proceed with the Bayesian classification. Different types of naive Bayes classifiers rest on different naive assumptions about the data.\n",
    "\n",
    "A Bernoulli Naive Bayes classifier is designed for binary/boolean features and this classifier is suitable for discrete data. The underlying assumption made by this model is that the data is distributed according to multivariate Bernoulli distributions. See [Bernoulli Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#bernoulli-naive-bayes) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48509b",
   "metadata": {
    "id": "da48509b"
   },
   "source": [
    "**Question**:\n",
    "- Import the `BernoulliNB` from the `sklearn.naive_bayes` module. [See documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)\n",
    "- Create a new BernoulliNB object named `nb_clf`\n",
    "- Fit the model on the data\n",
    "- Which are the most significant tokens for stances EENS and ONEENS for this classifier? One way to measure the importance of features, is to compute the ratio of their conditional probabilities for each label. You can access the log of the conditional probabilities learned for each feature and each class using `nb_clf.feature_log_prob_`. Implement the formula below to assess which features lead to the highest difference (important for the EENS class) and which lead to the lowest/most negative (important for the ONEENS class). Again, translate these feature indices to the tokens they correspond to using the `inverted_vocab`.\n",
    "\n",
    "$$\\frac{P({\\rm x}~|~y = \\text{EENS})}{P({\\rm x}~|~y = \\text{ONEENS})}$$\n",
    "\n",
    "$$ log(P({\\rm x}~|~y = \\text{EENS})) - log(P({\\rm x}~|~y = \\text{ONEENS})) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded8651",
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1707855819647,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "bded8651"
   },
   "outputs": [],
   "source": [
    "# import Bernoulli NB classifier and fit on your data\n",
    "# nb_clf = ...\n",
    "\n",
    "# agree_features = ... # list of 10 token ids, ordered from highest to lower importance assigned by the model for the \"AGREE\" class\n",
    "# disagree_features = ... # list of 10 token ids, ordered from highest to lower importance assigned by the model for the \"DISAGREE\" class\n",
    "\n",
    "# agree_tokens = ... # list of 10 tokens, ordered from highest to lower importance assigned by the model for the \"AGREE\" class\n",
    "# disagree_tokens = ... # list of 10 tokens, ordered from highest to lower importance assigned by the model for the \"DISAGREE\" class\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddea06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1707855821431,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "ebddea06",
    "outputId": "8abb8256-872b-4d2b-a912-120bb3bdcd47"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert type(nb_clf) == sklearn.naive_bayes.BernoulliNB, \"Wrong classifier\"\n",
    "assert abs(nb_clf.feature_log_prob_[0][2] - (-4.6693)) <= 1e-4, \"Have you fit the classifier? Have you set the seed? Are you working in colab?\"\n",
    "assert agree_features[0] == 1985, 'use np.argsort to get list of agree token ids'\n",
    "assert disagree_features[0] == 1068, 'use np.argsort to get list of disagree token ids'\n",
    "assert agree_tokens[0] == 'houdafstand', 'use the inverted vocabulary to map ids to tokens'\n",
    "assert disagree_tokens[0] == 'dictatuur' , 'use the inverted vocabulary to map ids to tokens'\n",
    "\n",
    "print(\"well done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5abba5",
   "metadata": {
    "id": "6a5abba5"
   },
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8c1bb",
   "metadata": {
    "id": "4ad8c1bb"
   },
   "source": [
    "Once the model is trained, the main task of supervised machine learning is to evaluate it based on what it says about new data that was not part of the training set. In Scikit-Learn, this can be done using the `predict()` method for classifiers. For the sake of this example, our \"new data\" will be a grid of x values, and we will ask what y values the model predicts (*system output labels*). We will then compare the model's predicted values to the known ground-truth values (*gold standard labels*) and evaluate how far off the model is through some metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83a3b7",
   "metadata": {
    "id": "fe83a3b7"
   },
   "source": [
    "Metrics: **Accuracy, Precision, Recall, F$_1$**\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/xhjwoqd6tnxxaeb/bowman_metrics.png?dl=1\" width=800px>\n",
    "\n",
    "$$F_1 = \\frac{2 * Precision * Recall}{Precision + Recall}$$\n",
    "\n",
    "Now we import all the metrics mentioned above from the `sklearn.metrics` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4400f",
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1707855827235,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "a2f4400f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f85cf",
   "metadata": {
    "id": "e62f85cf"
   },
   "source": [
    "**Question**: Define a new LogisticRegressionClassifier object (with inverse of regularization strength of 10) and fit it on the data, as before. **Don't forget to set the `random_state` argument to SEED again**. Then, evaluate it on the same data it was trained on by using `clf.predict()`. Use the accuracy score as an evaluation metric. Also use `classification_report` to print the performance as assessed by other metrics (precision, recall, f1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8da91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1707855831248,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "ffe8da91",
    "outputId": "0128a294-b0fd-4ffb-dabe-8d017ff3283c"
   },
   "outputs": [],
   "source": [
    "# import Logistic regression classifier and fit on your data\n",
    "# clf = ... (random_state=SEED)\n",
    "# acc_score = ...\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b46cee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1707855835628,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "53b46cee",
    "outputId": "f52f413b-287f-4bd7-dd3b-8a6c82465ce8"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert type(clf) == sklearn.linear_model._logistic.LogisticRegression, \"Wrong model\"\n",
    "assert clf.C==10.0, \"Set inverse of regularization strength to 10.0\"\n",
    "assert abs(acc_score-0.9945) <= 1e-4, 'Accuracy score is not correct. Have you set the seed? Are you working in colab?'\n",
    "\n",
    "print('well done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c2034",
   "metadata": {
    "id": "860c2034"
   },
   "source": [
    "Issue: the training error is a __biased__ estimate of the generalization error. As the model has seen the training data before, it will be better at predicting the labels for the dataset it was fitted on than at predicting labels for unseen data. By only evaluating the model on data it has already seen during the training stage, we won't get an accurate idea of how well it would perform on unseen data.\n",
    "\n",
    "Solution: Divide ${\\cal D}$ into disjoint parts called training and test sets (a common choice is using 80% for training and 20% for test).\n",
    "- Use the training set for fitting the model;\n",
    "- Use the test set for evaluation only, thereby yielding an unbiased estimate.\n",
    "\n",
    "This could be done by hand, but it is more convenient to use the `train_test_split` utility function from `sklearn.model_selection`.\n",
    "\n",
    "**Question**:\n",
    "- import the `train_test_split` function from the `sklearn.model_selection` module\n",
    "- Create a `X_train`, `X_val`, `y_train` and `y_val` set from the data collection, using 80% for training and 20% for test (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). **Please do not forget to set the `random_state` argument equal to SEED**.\n",
    "- Print the shapes of the new arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131118a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1707855845848,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "4131118a",
    "outputId": "bbf17b9f-a4a5-42a4-a5be-05eefec67417"
   },
   "outputs": [],
   "source": [
    "## import train/test split from sklearn\n",
    "## split X,y into test and train (random_state=SEED)\n",
    "## X_train, X_val, y_train, y_val = ...\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7948773",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1707855849085,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "c7948773",
    "outputId": "eaca6fa1-bf26-4a35-9793-571f3ef86aa9"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert X_train.shape == (2908, 5000), \"Train shape incorrect, have you performed an 80/20 split?\"\n",
    "assert y_train.shape == (2908,), \"Train shape incorrect, have you performed an 80/20 split?\"\n",
    "assert X_val.shape == (728, 5000), \"Val shape incorrect, have you performed an 80/20 split?\"\n",
    "assert y_val.shape == (728,), \"Val shape incorrect, have you performed an 80/20 split?\"\n",
    "\n",
    "print('well done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d08ea",
   "metadata": {
    "id": "a32d08ea",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question**: Now find out how well we do on held-out data. Train a Logistic regression classifier on the training set, again using an inverse regularization strength of 10 and setting the `random_state` equal to SEED. Evaluate its performance on both train and test data by using `clf.predict` and calculating the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926a41f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1707855852622,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "9926a41f",
    "outputId": "7a76e791-578a-48a1-9e99-286dd8ac8b77"
   },
   "outputs": [],
   "source": [
    "# create LogisticRegression classifier (random_state=SEED)\n",
    "# fit it on X_train, y_train\n",
    "# evaluate on X_val, y_val\n",
    "\n",
    "# train_acc_score = ...\n",
    "# val_acc_score = ...\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8836252",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1707855857922,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "f8836252",
    "outputId": "521ac9e6-1b11-4f4a-b2c7-46b26639e483"
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "\n",
    "assert type(clf) == sklearn.linear_model._logistic.LogisticRegression, \"Wrong model\"\n",
    "assert clf.C==10.0, \"set strength to 10.0\"\n",
    "assert abs(train_acc_score-0.9952) <= 1e-3 , \"train acc is not correct, random state (both in clf and in train-val split)? strength?\"\n",
    "assert abs(val_acc_score-0.6593) <= 1e-3 , \"valid acc is not correct, random state (both in clf and in train-val split)? strength?\"\n",
    "\n",
    "print('well done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d11c1",
   "metadata": {
    "id": "375d11c1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We see a big drop in accuracy on held-out data, meaning we overfit the training data.\n",
    "\n",
    "We can go back and revise our approach (e.g. by playing around with the different parameters for the [logistic regression classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model) and re-fitting on the training data, and then see how well we do on the held-out test data.\n",
    "\n",
    "By doing this, however, we'll be fitting to the test data. At some point, we'll want to evaluate on completely new data, which was the purpose of the test set in the first place! For this reason, the test split should be used as sparingly as possible, and we should hold back from using the test split to make any decisions about our model. Instead, we should split off another set of data which can be used in the iterative process of finding the best model. This set of data is called the validation set. We will address this approach in further detail in the next section.\n",
    "<img src=\"https://www.kdnuggets.com/wp-content/uploads/train_test_split.jpg\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b003168",
   "metadata": {
    "id": "4b003168"
   },
   "source": [
    "## 6. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa8b2d",
   "metadata": {
    "id": "16fa8b2d"
   },
   "source": [
    "### 6.1. Bias-variance tradeoff\n",
    "\n",
    "When models have enough flexibility to nearly perfectly account for the fine features in the data, they\n",
    "can learn to very accurately describe the training data. The model's precise form can become more reflective of the particular noise properties of the training data (which will be different in held-out data) than the intrinsic properties of whatever process generated that data (i.e., the actual 'signal' in the data, which will be present in held-out data as well).\n",
    "\n",
    "Such a model is said to __*overfit*__ the data: that is, it has so much model flexibility that the model ends up accounting for random errors as well as the underlying data distribution; another way of saying this is that the model has high __*variance*__, and it may poorly perform on unseen data.\n",
    "\n",
    "A model is said to __*underfit*__ the data when it does not have enough model flexibility to suitably account for all the features in the data; another way of saying this is that the model has high __*bias*__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b56bc5",
   "metadata": {
    "id": "29b56bc5"
   },
   "source": [
    "Overfitting can be countered in many ways.  In this tutorial we focus on the technique of __*regularization*__ of a logistic regression classifier.\n",
    "Learning in Logistic Regression is formulated as the optimization of\n",
    "\n",
    "$$ \\underbrace{\\underset{\\text{w}\\in R^{|V|}}{min}\\sum_{i}^{N} log(1+e^{{-(\\sigma(w^Tx))}})}_{Loss}$$\n",
    "\n",
    "When a linear model overfits, weights tend to become very large. One way to counter this, is to penalize large weights by adding an additional component to the loss function called a regularization.\n",
    "\n",
    "$$ \\underbrace{\\underset{\\text{w}\\in R^{|V|}}{min}\\sum_{i}^{N} log(1+e^{{-(\\sigma(w^Tx))}})}_{Loss} + \\underbrace{\\frac{1}{C} ||w||^2}_{Regularization}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c747d9",
   "metadata": {
    "id": "29c747d9"
   },
   "source": [
    "**Question**: What is the effect of the `C` parameter on the generalization performance? Evaluate in terms of accuracy, as well as the distribution of the weight coefficients. You can visualize the distribution by making a histogram (see, for example, the `distplot` function from the [Seaborn](https://seaborn.pydata.org/generated/seaborn.distplot.html) library).\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc22734",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1707855864689,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "9fc22734",
    "outputId": "66f7bf2b-358a-4c87-f744-5b733190d41e"
   },
   "outputs": [],
   "source": [
    "# import logistic regression\n",
    "# visualize coef distribution for different values of C (random_state=SEED)\n",
    "# evaluate acc on each value\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919274fb",
   "metadata": {
    "id": "919274fb"
   },
   "source": [
    "Fundamentally, the question of \"the best model\" is about finding a sweet spot in the tradeoff between *bias* and *variance*. This is called the **bias-variance tradeoff**.\n",
    "\n",
    "- *Underfitting, High Bias*: the model is too simple and does not capture the true relation between X and Y.\n",
    "- *Overfitting, High Variance*: the model is too specific to the training set and does not generalize.\n",
    "\n",
    "Below, we plot the training accuracy and validation accuracy for different values of the parameter C. Plots like this can help you decide which value of C (or other parameters) leads to the best performance of the model on unseen data.\n",
    "\n",
    "**Question**: Which value of C (from the range that is tried below) seems to be the best choice? Describe how you came to this conclusion.\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a737810",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "executionInfo": {
     "elapsed": 5612,
     "status": "ok",
     "timestamp": 1707855874204,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "2a737810",
    "outputId": "ce5b400e-3aa5-49ca-8aa2-ac8fa6af7e39"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluate parameter range in CV\n",
    "param_range = [0.0001,0.001,0.01,0.1,1,10,100]\n",
    "param_name = \"C\"\n",
    "clf = LogisticRegression()\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    clf, X, y,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range, cv=2, n_jobs=-1, scoring=\"accuracy\")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot parameter VS estimated error\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(param_name)\n",
    "plt.ylabel(\"score\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(min(param_range), max(param_range))\n",
    "plt.plot(param_range, train_scores_mean, color=\"blue\", label=\"Training acc.\")\n",
    "plt.fill_between(param_range,\n",
    "                 train_scores_mean + train_scores_std,\n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 alpha=0.2, color=\"blue\")\n",
    "plt.plot(param_range, test_scores_mean, color=\"red\", label=\"CV acc.\")\n",
    "plt.fill_between(param_range,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 alpha=0.2, color=\"red\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d3020",
   "metadata": {
    "id": "878d3020"
   },
   "source": [
    "<table>\n",
    "<tr><td><p style=\"clear: both;\"> <img src=\"https://www.dropbox.com/s/mpmrstr7k5z0lku/jakevdp_biasvariance.png?dl=1\" width=400px></td><td> <img src=\"https://www.dropbox.com/s/4dyuvb3b6swwcgy/louppe_bv.png?dl=1\" width=400px> <td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dabaeb",
   "metadata": {
    "id": "14dabaeb"
   },
   "source": [
    "### 6.2. Cross-validation\n",
    "\n",
    "When evaluating different settings (___hyperparameters___) for estimators, such as the $C$ setting that must be manually set for a logistic regression, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can ___leak___ into the model and evaluation metrics no longer report on generalization performance. To solve this problem, the data not used for training is split into a ___validation set___ and the actual ___test set___. Training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "\n",
    "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "A solution to this problem is a procedure called __cross-validation__ (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into $k$ smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k âfoldsâ:\n",
    "- A model is trained using all but one of the folds as training data;\n",
    "- The resulting model is evaluated on the remaining part of the data (i.e., it is used as a validation set to compute a performance measure such as accuracy).\n",
    "- The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop.\n",
    "\n",
    "This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/132oue6yj29cml3/jakevdp_cross.png?dl=1\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f697fa",
   "metadata": {
    "id": "b6f697fa"
   },
   "source": [
    "**Question**: What is the average accuracy over five folds of training, for a logistic regression classifier (with inverse regularization strength set to 10 and the `random_state` argument set to SEED)? Use the `cross_val_score` function from the `sklearn.model_selection` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758126d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3556,
     "status": "ok",
     "timestamp": 1707855890272,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "f758126d",
    "outputId": "334c71c9-2f76-4db4-e6ec-e505f1671e46",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import cross_val_score\n",
    "# clf = ...\n",
    "# avg_acc = ...\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db4182",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1707855901638,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "a8db4182",
    "outputId": "97c278c5-0410-4c76-860f-b841c734f122",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "## DON'T CHANGE THIS CELL IN ANY WAY\n",
    "assert type(clf) == sklearn.linear_model._logistic.LogisticRegression, \"wrong model\"\n",
    "assert clf.C==10.0, \"set strength to 10.0\"\n",
    "assert abs(avg_acc-0.652) <=1e-3, 'cross val score is not correct, make sure to set random_state=SEED and use 5 folds'\n",
    "\n",
    "print('well done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797863c1",
   "metadata": {
    "id": "797863c1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://www.dropbox.com/s/6qqluvighbqub27/epfl_traintest.PNG?dl=1\" width=600px>\n",
    "\n",
    "__Summary__: Beware of bias when you estimate model performance:\n",
    "* Training score is often an optimistic estimate of the true performance;\n",
    "* __The same data should not be used both for training and evaluation.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b5142",
   "metadata": {
    "id": "d49b5142"
   },
   "source": [
    "You will now attempt to train a model which performs well on the train set and generalizes well to the test set.\n",
    "\n",
    "A held-out collection of tweets is stored in `test.csv`, without the correct labels. This will serve as our test set. Note that this means you can use the entire data set, now stored in `data`, to train and validate your models (meaning you don't have to split off a test set, as we did earlier, just perform cross validation). Try to maximize your model's performance on the cross-validation splits without evaluating on the test set. Answer the questions below and let them guide you to the best model.\n",
    "\n",
    "Once you have selected and trained a decent model, you can use it to make predictions on the test set. In the second cell below, we show an example of how to do this and how to prepare a submission for the Kaggle competition.\n",
    "\n",
    "**Question**:\n",
    "1. Experiment with other measures for regularization of the models  discussed during the session\n",
    "    - What is `l1` and `l2` regularization and what is the effect on the weights when changing the `penalty` parameter of the LogisticRegression object to `l1`?\n",
    "    - What is the effect of the `max_features` parameter of the tokenizer?\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**\n",
    "2. Which of the models performs best on the validation data? Discover and import other models from the sklearn package ([KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier), [Random Forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), ...)\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**\n",
    "3. Can you think of ways to combine predictions by different classifiers?\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**\n",
    "4. You are free to think of other ways to improve your model as well (feature engineering, modeling, optimization, etc.). Please motivate any decisions you made to find the best model and approaches you tried.\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c00434",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41231,
     "status": "ok",
     "timestamp": 1707855946253,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "a5c00434",
    "outputId": "92b03832-efd6-45c2-eb43-9d2e387fcfc2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import models from the sklearn library\n",
    "# experiment with other regularization measures\n",
    "# discover other models and try them out\n",
    "# try to combine predictions by different classifiers\n",
    "# use cross-validation to select regularization parameters and compare models\n",
    "\n",
    "############### for student ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f103c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 6100,
     "status": "ok",
     "timestamp": 1707856090117,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "73f103c0"
   },
   "outputs": [],
   "source": [
    "# Make predictions for the test set and prepare submission for Kaggle competition\n",
    "\n",
    "test_path = \"test.csv\"\n",
    "\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "X_test = tokenizer.transform(test_data['text']) # transform test entries to feature representation\n",
    "                                                # make sure you have trained the tokenizer using all train data\n",
    "\n",
    "clf = LogisticRegression() # just a placeholder classifier, replace this with your best model and fit on all training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test = clf.predict(X_test) # make predictions for the test data\n",
    "                             # alternative: use predict_proba() to return probabilities for each class instead of labels and manually select most likely label from this information\n",
    "                             # make sure you have trained the classifier using all train data and optimized its parameters\n",
    "\n",
    "test_data['label'] = y_test\n",
    "test_data[['id','label']].to_csv('submission.csv',header=['id','label'], index = False) # kaggle submission is CSV containing two columns: entry ID and predicted label\n",
    "                                                                                        # labels are compared to ground truth in Kaggle, yielding a test score for your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409fd76",
   "metadata": {
    "id": "e409fd76"
   },
   "source": [
    "## 7. Bonus: Kaggle competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733dc4f9",
   "metadata": {
    "id": "733dc4f9"
   },
   "source": [
    "- Congratulations! You have made your first stance detection classifier and predicted the stance towards social distancing for a collection of new tweets. The ground truth for the held-out test data is stored on the online data science platform Kaggle.\n",
    "- We have already submitted the example submission formed above as a baseline in the competition. Simple improvements over the default settings should already result in higher scores than the baseline.\n",
    "- What is the performance of your model? How do you rank among your peers?\n",
    "- Now try to improve your model by adding new models, vectorizers, extra features, additional data... (talk to us or go looking online to get ideas). Do not hesitate to take it beyond the mere linear models, if you already have experience with more powerful models.\n",
    "- Think of ways to include knowledge from external sources in your model.\n",
    "- Submit your predictions to the in-class [Kaggle Competition](https://www.kaggle.com/competitions/u-gent-nlp-2025-competition). This competition is private and will be removed. We will keep it open up until the deadline for submitting this notebook (i.e., Friday February 21 at 11:59PM).\n",
    "- Feel free to comment on any successful submissions, or provide insights into which methods worked better than others. However, this remains optional.\n",
    "\n",
    "__Keep in mind, the limit of submissions is set at 20 per day!__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc9721",
   "metadata": {
    "id": "fdbc9721"
   },
   "source": [
    "## Acknowledgment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f78a1d",
   "metadata": {
    "id": "c7f78a1d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "If you received help or feedback from fellow students, or made use of generative language models to generate python code, please acknowledge that here (we're not as much encouraging the use of ChatGPT, but we are interested in your experiences if you did use it).\n",
    "\n",
    "We count on your academic honesty:\n",
    "\n",
    "**<font color=blue><<< INSERT ANSWER HERE >>></font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9629ed9",
   "metadata": {
    "id": "e9629ed9"
   },
   "source": [
    "## Data\n",
    "```\n",
    "Erik Tjong Kim Sang, Marijn Schraagen, Shihan Wang and Mehdi Dastani,\n",
    "Transfer Learning for Stance Analysis in COVID-19 Tweets.\n",
    "CLIN 2021.\n",
    "```\n",
    "[https://ifarm.nl/erikt/papers/clin-20210419.pdf](https://ifarm.nl/erikt/papers/clin-20210419.pdf)\n",
    "\n",
    "## Tutorial based on\n",
    "\n",
    "- [NYU Course - Introduction to Natural Language Understanding - Samuel Bowman](https://docs.google.com/document/d/1kXhxA4iit2fhAJJGOb32bb151cKLJtW8xWuyMVwqD6s/edit)\n",
    "- [Introduction to Scikit Learn - Gilles Louppe](https://github.com/glouppe/tutorials-scikit-learn)\n",
    "- [EPFL Introduction to Deep Learning - FranÃ§ois Fleuret](https://fleuret.org/ee559/)\n",
    "- [Machine learning for NLP - Benjamin Muller](https://nlp-ensae.github.io/files/NLP-ENSAE-2021-lecture-1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kC0NwjqHMbyh",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707855953929,
     "user": {
      "displayName": "Thomas Demeester",
      "userId": "17040482890485826117"
     },
     "user_tz": -60
    },
    "id": "kC0NwjqHMbyh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
